{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Noise Model using Calibration Data \n",
    "\n",
    "We will use pairs of noisy calibration observations $x_i$ and clean signal $s_i$ (created by averaging these noisy, calibration images) to estimate the conditional distribution $p(x_i|s_i)$. Histogram-based and Gaussian Mixture Model-based noise models are generated and saved. \n",
    "\n",
    "__Note:__ Noise model can also be generated if calibration data is not available. In such a case, we use an approach called ```Bootstrapping```. Take a look at the notebook ```0b-CreateNoiseModel (With Bootstrapping)``` on how to do so. To understand more about the ```Bootstrapping``` procedure, take a look at the readme [here](https://github.com/juglab/PPN2V)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "from torch.distributions import normal\n",
    "import matplotlib.pyplot as plt, numpy as np, pickle\n",
    "from scipy.stats import norm\n",
    "from tifffile import imread\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from divnoising.gaussianMixtureNoiseModel import GaussianMixtureNoiseModel\n",
    "from divnoising import histNoiseModel\n",
    "from divnoising.utils import plotProbabilityDistribution\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "Download the data from https://zenodo.org/record/5156960/files/Mouse%20skull%20nuclei.zip?download=1. Here we show the pipeline for Mouse nuclei dataset. Save the dataset in an appropriate path. For us, the path is the data folder which exists at `./data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('./data')\n",
    "\n",
    "zipPath=\"./data/Mouse_skull_nuclei.zip\"\n",
    "if not os.path.exists(zipPath):  \n",
    "    data = urllib.request.urlretrieve('https://zenodo.org/record/5156960/files/Mouse%20skull%20nuclei.zip?download=1', zipPath)\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise model is a characteristic of your camera and not of the sample. The downloaded data folder contains a set of calibration images (For the Mouse nuclei dataset, it is ```edgeoftheslide_300offset.tif``` showing the edge of a slide and the data to be denoised is named ```example2_digital_offset300.tif```). The calibration images can be anything which is static and imaged multiple times in succession. Thus, the edge of slide works as well. We can either bin the noisy - GT pairs (obtained from noisy calibration images) as a 2-D histogram or fit a GMM distribution to obtain a smooth, parametric description of the noise model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify ```path``` where the noisy calibration data will be loaded from. It is the same path where noise model will be stored when created later, ```dataName``` is the name you wish to have for the noise model,  ```n_gaussian``` to indicate how many Gaussians willbe used for learning a GMM based noise model, ```n_coeff``` for indicating number of polynomial coefficients will be used to patrametrize the mean, standard deviation and weight of GMM noise model. The default settings for ```n_gaussian``` and ```n_coeff``` generally work well for most datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"./data/Mouse_skull_nuclei/\"\n",
    "observation= imread(path+'edgeoftheslide_300offset.tif') # Load the appropriate calibration data\n",
    "\n",
    "dataName = 'nuclei' # Name of the noise model \n",
    "n_gaussian = 3 # Number of gaussians to use for Gaussian Mixture Model\n",
    "n_coeff = 2 # No. of polynomial coefficients for parameterizing the mean, standard deviation and weight of Gaussian components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nameHistNoiseModel ='HistNoiseModel_'+dataName+'_'+'calibration'\n",
    "nameGMMNoiseModel = 'GMMNoiseModel_'+dataName+'_'+str(n_gaussian)+'_'+str(n_coeff)+'_'+'calibration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data contains 100 images of a static sample (edge of a slide).\n",
    "# We estimate the clean signal by averaging all images.\n",
    "\n",
    "signal=np.mean(observation[:, ...],axis=0)[np.newaxis,...]\n",
    "\n",
    "# Let's look the raw data and our pseudo ground truth signal\n",
    "print(signal.shape)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(label='average (ground truth)')\n",
    "plt.imshow(signal[0],cmap='gray')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(label='single raw image')\n",
    "plt.imshow(observation[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Histogram Noise Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a histogram based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We set the range of values we want to cover with our model.\n",
    "# The pixel intensities in the images you want to denoise have to lie within this range.\n",
    "minVal, maxVal = 2000, 22000\n",
    "bins = 400\n",
    "\n",
    "# We are creating the histogram.\n",
    "# This can take a minute.\n",
    "histogram = histNoiseModel.createHistogram(bins, minVal, maxVal, observation,signal)\n",
    "\n",
    "# Saving histogram to disc.\n",
    "np.save(path+nameHistNoiseModel+'.npy', histogram)\n",
    "histogramFD=histogram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the histogram-based noise model.\n",
    "plt.xlabel('Observation Bin')\n",
    "plt.ylabel('Signal Bin')\n",
    "plt.imshow(histogramFD**0.25, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the GMM noise model\n",
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a GMM based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_signal=np.min(signal)\n",
    "max_signal=np.max(signal)\n",
    "print(\"Minimum Signal Intensity is\", min_signal)\n",
    "print(\"Maximum Signal Intensity is\", max_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating the noise model training for `n_epoch=4000` and `batchSize=25000` works the best for `Mouse nuclei` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussianMixtureNoiseModel = GaussianMixtureNoiseModel(min_signal = min_signal, max_signal =max_signal, \n",
    "                                                      path=path, weight = None, n_gaussian = n_gaussian, \n",
    "                                                      n_coeff = n_coeff, min_sigma = 50, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussianMixtureNoiseModel.train(signal, observation, batchSize = 25000, n_epochs = 4000, \n",
    "                                learning_rate=0.1, name = nameGMMNoiseModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Histogram-based and GMM-based noise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotProbabilityDistribution(signalBinIndex=170, histogram=histogramFD, \n",
    "                            gaussianMixtureNoiseModel=gaussianMixtureNoiseModel, min_signal=minVal, \n",
    "                            max_signal=maxVal, n_bin= bins, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
