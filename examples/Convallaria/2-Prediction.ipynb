{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DivNoising - Prediction\n",
    "This notebook contains an example on how to use a previously trained DivNoising VAE to denoise images.\n",
    "If you haven't done so please first run ```0-CreateNoiseModel.ipynb``` and ```1-Training.ipynb```, which will download the data, create a noise model and train the DivNoising model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import all our dependencies.\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from divnoising import utils\n",
    "from nets import lightningmodel\n",
    "from glob import glob\n",
    "from tifffile import imread\n",
    "from matplotlib import pyplot as plt\n",
    "device = torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data to predict on\n",
    "The data should be present in the directory specified by ```noisy_data_path``` and the ```noisy_input``` is the name of the image in this directory that needs to be denoised. \n",
    "This notebook expects 2D datasets in ```.tif``` format. If your data is a stack of 2D images, you can load it as shown in the next cell. If you dataset has multiple individual 2D tif files, comment out the second line in the cell below and uncomment the third line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noisy_data_path=\"data/Convallaria_diaphragm/\"\n",
    "noisy_input= imread(noisy_data_path+'20190520_tl_25um_50msec_05pc_488_130EM_Conv.tif').astype(np.float32)\n",
    "# noisy_input= imread(noisy_data_path+'*.tif').astype(np.float32) # To load multiple individual 2D tif images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load our model\n",
    "We load the last weights of the trained model from the ```basedir```. The ```basedir``` should be the same which you specified in the training notebook `1-Training.ipynb`. Also specify the ```model_name```. It should be the same as specified in the training notebook `1-Training.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "basedir = 'models'\n",
    "model_name = 'divnoising_convallaria_demo'\n",
    "\n",
    "name = glob(basedir+\"/\"+model_name+'_last.ckpt')[0]\n",
    "vae = lightningmodel.VAELightning.load_from_checkpoint(checkpoint_path = name)\n",
    "if not torch.cuda.is_available():\n",
    "    raise ValueError(\"GPU not found, predictions will run on CPU and can be somewhat slow!\")\n",
    "else:\n",
    "    vae.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we predict some qulitative diverse solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_qualitative_results(noisy_input,vae,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict denoised images and (optionally) save them\n",
    "Specify how many denoised samples need to be predicted for each noisy image by specifying the parameter ```num_samples```. Also MMSE denoised estimate will be computed using these many samples.  \n",
    "\n",
    "If you do not want access to different samples but just need the MMSE denoised estimate, set the paarmeter ```returnSamples=False```.\n",
    "\n",
    "You can also save the denoised results (both samples and MMSE estimate for each noisy image) by providing the ```export_results_path``` which is the directory where the results should be saved.\n",
    "\n",
    "Alternatively, you can also export the MMSE estimate and only a fraction of the samples used for computing MMSE estimate for each image by specifying the parameter ```fraction_sample_to_export```. If set to $0$, none of the samples are exported and only the MMSE estimate is exported, whereas setting it to $1$ exports all samples used for computing MMSE estimate.\n",
    "\n",
    "If you only want to export MMSE estimate, set parameter ```export_mmse``` to True. If you do not want to export MMSE estimate, set it to ```False```.\n",
    "\n",
    "The parameter ```tta``` refers to test time augmentation which may improve performance of DivNoising even further but will take ```8x``` longer to predict. This is enabled by default. If you wish to disable it, set it to ```False```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "export_results_path = \"denoised_results\"\n",
    "fraction_samples_to_export = 0\n",
    "export_mmse = False\n",
    "tta = True\n",
    "mmse_results = utils.predict_and_save(noisy_input[:5],vae,num_samples,device,\n",
    "                                fraction_samples_to_export,export_mmse,export_results_path,tta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute PSNR\n",
    "Here we compute Peak Signal-to-Noise Ratio (PSNR) of the denoised MMSE output with respect to the available GT data specified by the ```gt``` parameter in the next cell. If you do not have GT data, do not run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSNRs=[]\n",
    "gt=np.mean(noisy_input[:,...],axis=0)[np.newaxis,...]\n",
    "\n",
    "for i in range(len(mmse_results)):\n",
    "    psnr=utils.PSNR(gt[0],mmse_results[i])\n",
    "    PSNRs.append(psnr)\n",
    "    print(\"image:\", i, \"psnr:\"+format(psnr,\".3f\")+ \"\\t mean psnr:\"+format(np.mean(PSNRs),\".3f\")) \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "print('mean',np.mean(PSNRs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lightning",
   "language": "python",
   "name": "lightning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
